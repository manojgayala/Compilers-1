
# Introduction

This is a report about the various options in common compilers like gcc, llvm etc. It also covers the front ends, back ends supported by illustrating examples and covers the optimization techniques offered by these compilers.

  

# Options in GCC

There are many options provided by gcc but we will cover few of the important and frequently used ones.

  

- *Output file name*

This can be used to set the specific name to the output file and also we could direct it to a location where we want to create this file.

```

$ gcc helloWorld.c -o output

```

  
  

- *Enabling warnings*

```

int main(int argc, char* argv[])

{

int x;

printf("%d",x);

return 0;

}

```

If we run this normally, we get garbage value printed on console whereas when we enable warnings we get output as follows

```

$ gcc -Wall test.c -o test

test.c: In function ‘main’:

test.c:8:5: warning: ‘x’ is used uninitialized in this function [-Wuninitialized]

8 | printf("%d",x);

| ^~~~~~~~~~~~~~

```

These warnings can also be converted to errors using -Werror option.

```

$ gcc -Wall -Werror test.c -o test

```

- *Producing code at intermediate levels*

GCC provides us the options to generate the code at intermediate stages. We can use certain flags to make sure we get the necessary files.

```

$ gcc -E test.c > test.i # for preprocessed stage output

$ gcc -S test.c > test.s # for assembly code

$ gcc -C test.c # compiled code named as test.o is created

$ gcc -save-temps test.c # creates all intermediate files

```

  

- *Library creation and linking*

The libraries can be created with virtual address spaces and could be linked with codes to produce the final executable.

```

$ gcc -c -Wall -fPIC file.c

$ gcc -shared -o Libfile.so file.o  # creates a shared library file

$ gcc -Wall test.c -o test -lLibfile  # links with test.c

```

- *Compile time Macros*

The macros can be defined at compile time using -D compiler option.

```

$ gcc -Wall -DPI test.c -o test

```

All these options can be written to a file named c_cmds and this could be provided during compilation using @ option.

```

$ cat c_cmds

-Wall -o test

  

$ gcc test.c @c_cmds  # options in c_cmds would be used

```

  

# Options in LLVM

Just like GCC, LLVM also provides a wide range of options for users during compilation. Clang is the front end for LLVM in compilation of C class of languages. These are some of the options provided by LLVM.

  

- *Exceptional warnings*

There is an option to make sure some warnings remain the same even if all warnings are converted to error by compiler option Werror using Wno-error.

```

$ clang -Wall -Wno-error=uninitialized test.c  # the same test.c as above

test.c:8:17: warning: variable 'x' is uninitialized when used here [-Wuninitialized]

printf("%d",x);

```

- *fsyntax-only*

This option makes sure that only preprocessing, parsing and type checking stages happen during compilation.

```

$ clang -fsyntax-only test.c -o test

$ ls

test.c

```

- *Standard specification*

LLVM provides us the option to choose our language standard for compilation. Some of the supported languages for C are c90, c99, gnu89, ISO C 99 etc.

```

$ clang --std c99 test.c -o test

```

- *Runtime linking*

There is an option using -rtlib which helps us to link the libraries at runtime.

  

- *fdiagnostics-format*

We can format the output of diagnostics using this command. Different options would yield different kinds of output.

```

$ clang -fdiagnostics-format=clang -Wall test.c

test.c:8:17: warning: variable 'x' is uninitialized when used here [-Wuninitialized]

printf("%d",x);

$ clang -fdiagnostics-format=msvc -Wall test.c

test.c(8,17): warning: variable 'x' is uninitialized when used here [-Wuninitialized]

printf("%d",x);

$ clang -fdiagnostics-format=vi -Wall test.c

test.c +8:17: warning: variable 'x' is uninitialized when used here [-Wuninitialized]

printf("%d",x);  # observe after test.c in first line of each warning

```

- *Optimization Techniques*

LLVM also provides the optimization for the code and we can view that data using certain options. Commands like -fsave-optimization-record to save the data into a separate file and specify the type of file as parameter to this option.

```

$ clang -fsave-optimization-record=bitstream test.c -o test

```

There are options to control the file location and name using -foptimization-record-file.

  

# Frontends supported

  

### GCC

GCC is a part of the GNU compiler collection. GCC mainly supports the frontends for

- C

- C++

- Fortran

- Objective C

- Ada

- Go

- D

  

Apart from this, there are many frontends written for GCC but are not integrated yet. Some of these are GNU Pascal compiler, Mercury, Cobol, GHDL compilers etc. These frontends form an IR (Intermediate Representation) which is fed to the middle end of GCC where the optimizations are done to improve quality and performance.

  

### LLVM

LLVM supports many frontends and CLang is one of them used for C. The other frontends are

- Ada

- C++

- D

- Delphi

- Fortran

- Haskell

- Objective-C

- Swift

- Rust

- Julia

  

The support for LLVM is increasing because it is introducing improvements to compilers to optimize code better. It also supports multithreading and easy integration with IDEs (Integrated Development Environments). The OpenMP is also supported by CLang especially.

  

# Code generation using backends

  

### GCC

We write a small C program that prints "Hello World!". Now we know that the GCC supports multiple backends for various architectures. Here we are going to cover only two architectures mainly, x86_64 and armv7l.

```

int main(int argc, char* argv[])

{

printf("Hello World!\n");

return 0;

}

```

Compiling this program to support x86_64 architecture

```

$ gcc test.c -o main-x86

```

We can verify this by looking at the executable file

```

$ file main-x86

main-x86: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=e5bc16cc1968435de5070b5e3104194a2772aead, for GNU/Linux 3.2.0, not stripped

```

Compiling this program to support armv7l architecture

```

$ arm-linux-gnueabi-gcc test.c -o main-arm -static

```

We can verify this by looking at the executable file

```

$ file main-arm

main-arm: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), statically linked, BuildID[sha1]=6b3284ff1624f5bbcc53655494f628bcdac39af9, for GNU/Linux 3.2.0, not stripped

```

It could be observed that the compilation using gcc has created an executable which runs only on x86_64 architecture because my laptop has that architecture. This implies that the second executable file cannot be run on my laptop and it was indeed observed.

```

$ ./main-arm

bash: ./main-arm: cannot execute binary file: Exec format error

```

### LLVM

Similar to the analysis of GCC, we begin with a C program to print "Hello World!". But there are a lot of issues with LLVM for cross compilation. General method on our computer architecture (x86_64) is simple as follows

```

$ clang --target=x86_64 test.c -o test

```

This creates an executable file named test which is as follows

```

$ file test

test: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=6496d758deb58ba8a406de3922b0abd7ad068a08, for GNU/Linux 3.2.0, not stripped

```

Following the same steps for the arm architecture would not be possible.

```

$ clang --target=arm test.c -o test

clang: warning: unknown platform, assuming -mfloat-abi=soft

clang: warning: unknown platform, assuming -mfloat-abi=soft

In file included from test.c:2:

/usr/include/pthread.h:657:6: error: 'regparm' is not valid on this platform

__cleanup_fct_attribute;

^~~~~~~~~~~~~~~~~~~~~~~

/usr/include/bits/pthreadtypes-arch.h:52:50: note: expanded from macro '__cleanup_fct_attribute'

# define __cleanup_fct_attribute __attribute__ ((__regparm__ (1)))

^ ~

In file included from test.c:2:

/usr/include/pthread.h:669:3: error: 'regparm' is not valid on this platform

__cleanup_fct_attribute;

^~~~~~~~~~~~~~~~~~~~~~~

/usr/include/bits/pthreadtypes-arch.h:52:50: note: expanded from macro '__cleanup_fct_attribute'

# define __cleanup_fct_attribute __attribute__ ((__regparm__ (1)))

^ ~

In file included from test.c:2:

/usr/include/pthread.h:710:6: error: 'regparm' is not valid on this platform

__cleanup_fct_attribute __attribute__ ((__noreturn__))

^~~~~~~~~~~~~~~~~~~~~~~

/usr/include/bits/pthreadtypes-arch.h:52:50: note: expanded from macro '__cleanup_fct_attribute'

# define __cleanup_fct_attribute __attribute__ ((__regparm__ (1)))

^ ~

3 errors generated.

```

The reason for this complication is the missing libraries which need to be installed. Unlike the gcc, there are many libraries and flags to be declared for the compilation to work. More details can be found [here](https://clang.llvm.org/docs/CrossCompilation.html).

  

# Optimization levels in Compilers

Compilers are not just translators, they even optimize the code to improve performance and quality. Some of the optimizations are common but some optimizations need user consent to proceed because **compiler should not change the semantics** of the user program.

The optimization is done in various levels and following examples provide the analysis of the same.

  

Main code is as follows

```

int arr[10000];

for(int i=0;i<10000;i++)

{

arr[i]= rand()%100;

}

  

int n = sizeof(arr)/sizeof(arr[0]);

bubbleSort(arr, n);

```

Without optimization, the runtime is as follows

##### GCC

```

$ gcc test.c -o Gen

$ ./Gen

Time : 0.414001sec

```

##### LLVM

```

$ clang test.c -o Gen

$ ./Gen

Time : 0.470768sec

```

  

### O0 optimization

##### GCC

```

$ gcc -O0 test.c -o Opt1

$ ./Opt1

Time : 0.413073sec

```

We can observe that there is only a slight decrease in the runtime in O0 optimization.

##### LLVM

```

$ clang -O0 test.c -o Opt1

$ ./Opt1

Time : 0.471443sec

```

There is no decrease in runtime but it could be due to the other processes running parallely on the machine. In general, there is not much difference.

  

### O1 optimization

##### GCC

```

$ gcc -O1 test.c -o Opt2

$ ./Opt2

Time : 0.176951sec

```

There is significant improvement in O1 optimization due to better binary code.

##### LLVM

```

$ clang -O1 test.c -o Opt2

$ ./Opt2

Time : 0.175511sec

```

The decrease in runtime is even better than GCC's O0 optimization.

  

### O2 optimization

##### GCC

```

$ gcc -O2 test.c -o Opt3

$ ./Opt3

Time : 0.173347sec

```

The improvement is slight but as the time taken increases for the code we can observe significant differences. Even if we run the code for a million times (practical scenario), the benefit from optimization is not negligible.

##### LLVM

```

$ clang -O2 test.c -o Opt3

$ ./Opt3

Time : 0.206333sec

```

The runtime has increased in LLVM's case unlike GCC. This could be due to the low execution time of the code, maybe for higher execution time codes this optimization is suitable.

  

### O3 optimization

##### GCC

```

$ gcc -O3 test.c -o Opt4

$ ./Opt4

Time : 0.172644sec

```

As the level of optimization is increased, the threshold is reached which is close to the minimum possible execution time.

##### LLVM

```

$ clang -O3 test.c -o Opt4

$ ./Opt4

Time : 0.135942sec

```

This is a drastic improvement in performance which can be explained by the better code generation then O2 which works even for lower timed programs. This is better than GCC's O3 which needs to be noted.

  

### Os optimization

##### GCC

```

$ gcc -Os test.c -o Opts

$ ./Opts

Time : 0.168540sec

```

The decrease in run time is significant (it is the average of multiple executions). This optimization seems to take time in compilation but it is worth using.

##### LLVM

```

$ clang -Os test.c -o Opts

$ ./Opts

Time : 0.203703sec

```

Unlike GCC, there is no decrease in runtime which is astonishing. There is no valid logical reasoning for this (from my side).

  

### Oz optimization

##### GCC

There is no such thing in GCC compiler. So we get an error when we try executing this.

##### LLVM

```

$ clang -Oz test.c -o Optz

$ ./Optz

Time : 0.152412sec

```

There is improvement in performance close to the best as of now (O3). This could outperform O3 for larger execution times.

  

## Inferences

##### GCC

Finally, we can conclude that Os is most optimal among these and trade off is between compile time and runtime but in real scenarios, we need to focus on runtime because a program is compiled once and run for multiple times. So based on the requirement, we should choose the optimization levels.

##### LLVM

The optimization in LLVM is better than GCC. There is no proper hierarchy in the optimization levels which seems intriguing. Apart from that we could choose O3 to be the best possible among all levels as of now.

  

# Conclusion

This report has covered many aspects of compilers and comparisons between GCC and LLVM. The choice of compiler is highly specific to requirements and we cannot judge them based on some programs or their architecture supports.

  

You can find this document on my github page [here](
